{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, itertools, json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def crawl_directory(dirname):\n",
    "    \"\"\" Walk a nested directory to get all filename ending in a pattern \"\"\"\n",
    "    for path, subdirs, files in os.walk(dirname):\n",
    "        for name in files:\n",
    "            if not name.endswith('.DS_Store'):\n",
    "                yield os.path.join(path, name)\n",
    "\n",
    "\n",
    "def remove_empty_dirs(path):\n",
    "    for root, dirnames, filenames in os.walk(path, topdown=False):\n",
    "        for dirname in dirnames:\n",
    "            remove_empty_dir(os.path.realpath(os.path.join(root, dirname)))\n",
    "\n",
    "\n",
    "def remove_empty_dir(path):\n",
    "    try:\n",
    "        os.rmdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def nested_pickle_dict():\n",
    "    \"\"\" Picklable defaultdict nested dictionaries \"\"\"\n",
    "    return defaultdict(nested_pickle_dict)\n",
    "\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return (a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_performance_multivariate(mypath):\n",
    "    \"\"\" For a trial, get the best performance for multivariate data \"\"\"\n",
    "    # Get path, files in path\n",
    "    files = os.listdir(mypath)\n",
    "    results = []\n",
    "\n",
    "    # Read in the files\n",
    "    for file in files:\n",
    "        if file == '.DS_Store':\n",
    "            continue\n",
    "                            \n",
    "        with open(mypath + file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        results.append(data)\n",
    "        \n",
    "    # Initialize best dictionary\n",
    "    optimal = nested_pickle_dict()\n",
    "\n",
    "    # Go through all models, distributionss, metrics, and record the best\n",
    "    for result in results:\n",
    "        for model, distributions in result.items():\n",
    "            for distribution, metrics in distributions.items():\n",
    "                for metric, values in metrics.items():\n",
    "                    if metric not in [\"LR\", \"HDIM\", \"BSIZE\"]:\n",
    "\n",
    "                        # If metric is seen for the first time, it is the best\n",
    "                        if metric not in optimal[model][distribution]:\n",
    "                            optimal[model][distribution][metric][\"value\"] = values\n",
    "                            optimal[model][distribution][metric][\"parameters\"] = [metrics[\"LR\"], metrics[\"HDIM\"], metrics[\"BSIZE\"]]\n",
    "\n",
    "                        # Otherwise, compare it the presently considered value\n",
    "                        elif min(optimal[model][distribution][metric][\"value\"]) > min(values):\n",
    "                            optimal[model][distribution][metric][\"value\"] = values\n",
    "                            optimal[model][distribution][metric][\"parameters\"] = [metrics[\"LR\"], metrics[\"HDIM\"], metrics[\"BSIZE\"]]\n",
    "\n",
    "    return optimal\n",
    "\n",
    "\n",
    "def get_best_performance_mnist(*args):\n",
    "    return get_best_performance_multivariate(*args)\n",
    "\n",
    "\n",
    "def merge_mixture(dirname):\n",
    "    outdir = dirname\n",
    "    for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        for nest in crawl_directory(dirname + file):\n",
    "\n",
    "            index = 1\n",
    "\n",
    "            if 'dims' not in nest.split('/')[7]:\n",
    "                outdir = '/'.join(nest.split('/')[:7] + nest.split('/')[8:9]) + '/'\n",
    "            else:\n",
    "                outdir = dirname\n",
    "                \n",
    "            # Initialize directory\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            try:\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "            except:\n",
    "                extension = nest.split('/')[-1]\n",
    "                while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                    index += 1\n",
    "\n",
    "                if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                    os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "    remove_empty_dirs(dirname)\n",
    "    \n",
    "    \n",
    "def merge_multivariate(dirname):\n",
    "    outdir = dirname\n",
    "    for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        for nest in crawl_directory(dirname + file):\n",
    "\n",
    "            index = 1\n",
    "\n",
    "            if 'dims' not in nest.split('/')[6]:\n",
    "                outdir = '/'.join(nest.split('/')[:7] + nest.split('/')[8:9]) + '/'\n",
    "            else:\n",
    "                # Uncomment the + for mixture\n",
    "                outdir = dirname + nest.split('/')[6] + '/'\n",
    "                \n",
    "            # Initialize directory\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            try:\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "            except:\n",
    "                extension = nest.split('/')[-1]\n",
    "                while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                    index += 1\n",
    "\n",
    "                if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                    os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "    remove_empty_dirs(dirname)\n",
    "    \n",
    "    \n",
    "def merge_mnist(dirname):\n",
    "    outdir = dirname\n",
    "    for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        for nest in crawl_directory(dirname + file):\n",
    "\n",
    "            index = 1\n",
    "\n",
    "            if 'dims' in nest.split('/')[5]:\n",
    "                outdir = '/'.join(nest.split('/')[:6]) + '/'\n",
    "            else:\n",
    "                # Uncomment the + for mixture\n",
    "                outdir = dirname + nest.split('/')[7] + '/'\n",
    "    \n",
    "\n",
    "            # Initialize directory\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            try:\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "            except:\n",
    "                extension = nest.split('/')[-1]\n",
    "                while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                    index += 1\n",
    "\n",
    "                if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                    os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "    remove_empty_dirs(dirname)\n",
    "    \n",
    "\n",
    "def get_stats(dirname):\n",
    "    \"\"\" Get missing runs for all trials \"\"\"\n",
    "    hidden_dims = [32, 64, 128, 256, 512]\n",
    "    batch_sizes = [128, 256, 512, 1024]\n",
    "    learning_rates = [2e-1, 2e-2, 2e-3]\n",
    "\n",
    "    filenames, hyperparams = [], []\n",
    "\n",
    "    for (lr, hdim, bsize) in itertools.product(*[learning_rates, hidden_dims, batch_sizes]):\n",
    "        hyperparam = (lr * min(batch_sizes)/bsize, hdim, bsize)\n",
    "        filename = 'results_{0}.json'.format(\"_\".join([str(i) for i in hyperparam]))\n",
    "        filenames.append(filename)\n",
    "        hyperparams.append((str(format_e(lr)), str(hdim), str(bsize)))\n",
    "    \n",
    "    TODO = []\n",
    "    for file in os.listdir(dirname):\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        print(file, len(os.listdir(dirname + file)))\n",
    "        idx = 0\n",
    "        try:\n",
    "            for f in os.listdir(dirname + file):\n",
    "                if '.DS_Store' in f:\n",
    "                    continue\n",
    "\n",
    "                files = os.listdir(dirname + file + '/' + f)\n",
    "                length = len(files)\n",
    "                print(f, length)\n",
    "\n",
    "                if length >= 60:\n",
    "                    idx += 1            \n",
    "                else:\n",
    "                    missing = [hyperparams[idx] for idx, item in enumerate(filenames) if item not in files]\n",
    "                    TODO.extend(missing)\n",
    "\n",
    "            print('{0}/20'.format(idx))\n",
    "            print('\\n')\n",
    "        except NotADirectoryError:\n",
    "            files = os.listdir(dirname + file)\n",
    "            missing = [hyperparams[idx] for idx, item in enumerate(filenames) if item not in files]\n",
    "            TODO.extend(missing)\n",
    "            \n",
    "        \n",
    "    return TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_1 60\n",
      "trial_10 60\n",
      "trial_11 60\n",
      "trial_12 60\n",
      "trial_13 60\n",
      "trial_14 60\n",
      "trial_15 60\n",
      "trial_16 57\n",
      "trial_17 55\n",
      "trial_2 60\n",
      "trial_3 60\n",
      "trial_4 60\n",
      "trial_5 60\n",
      "trial_6 60\n",
      "trial_7 60\n",
      "trial_8 60\n",
      "trial_9 60\n"
     ]
    }
   ],
   "source": [
    "TODO = get_stats('/Users/sob/Desktop/october/16_dims_100000_samples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TODO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirname = '/Users/sob/Desktop/october/64_dims_100000_samples/'\n",
    "# outdir = dirname\n",
    "# for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "#     if '.DS_Store' in file:\n",
    "#         continue\n",
    "\n",
    "#     for nest in crawl_directory(dirname + file):\n",
    "\n",
    "#         index = 1\n",
    "\n",
    "#         if 'dims' not in nest.split('/')[6]:\n",
    "#             outdir = '/'.join(nest.split('/')[:6]) + '/'# + nest.split('/')[8:9]) + '/'\n",
    "#         else:\n",
    "#             # Uncomment the + for mixture\n",
    "#             outdir = dirname + nest.split('/')[6] + '/'\n",
    "            \n",
    "#         print(outdir)\n",
    "            \n",
    "#        # Initialize directory\n",
    "#         if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "#             os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "#         try:\n",
    "#             shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "#         except:\n",
    "#             extension = nest.split('/')[-1]\n",
    "#             while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "#                 index += 1\n",
    "\n",
    "#             if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "#                 os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "#             shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "# remove_empty_dirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024_dims_10000_samples 2\n",
      "trial_1 34\n",
      "trial_2 34\n",
      "0/20\n",
      "\n",
      "\n",
      "1024_dims_1000_samples 10\n",
      "trial_1 52\n",
      "trial_10 1\n",
      "trial_2 51\n",
      "trial_3 51\n",
      "trial_4 50\n",
      "trial_5 50\n",
      "trial_6 1\n",
      "trial_7 1\n",
      "trial_8 1\n",
      "trial_9 1\n",
      "0/20\n",
      "\n",
      "\n",
      "128_dims_100000_samples 14\n",
      "trial_1 60\n",
      "trial_10 48\n",
      "trial_11 44\n",
      "trial_12 32\n",
      "trial_13 22\n",
      "trial_14 7\n",
      "trial_2 60\n",
      "trial_3 60\n",
      "trial_4 59\n",
      "trial_5 59\n",
      "trial_6 58\n",
      "trial_7 54\n",
      "trial_8 54\n",
      "trial_9 51\n",
      "3/20\n",
      "\n",
      "\n",
      "128_dims_10000_samples 10\n",
      "trial_1 60\n",
      "trial_10 60\n",
      "trial_2 60\n",
      "trial_3 60\n",
      "trial_4 60\n",
      "trial_5 60\n",
      "trial_6 60\n",
      "trial_7 60\n",
      "trial_8 60\n",
      "trial_9 60\n",
      "10/20\n",
      "\n",
      "\n",
      "16_dims_100000_samples 17\n",
      "trial_1 60\n",
      "trial_10 60\n",
      "trial_11 60\n",
      "trial_12 60\n",
      "trial_13 60\n",
      "trial_14 60\n",
      "trial_15 60\n",
      "trial_16 57\n",
      "trial_17 55\n",
      "trial_2 60\n",
      "trial_3 60\n",
      "trial_4 60\n",
      "trial_5 60\n",
      "trial_6 60\n",
      "trial_7 60\n",
      "trial_8 60\n",
      "trial_9 60\n",
      "15/20\n",
      "\n",
      "\n",
      "16_dims_10000_samples 8\n",
      "trial_1 60\n",
      "trial_2 60\n",
      "trial_20 60\n",
      "trial_3 60\n",
      "trial_4 60\n",
      "trial_5 60\n",
      "trial_6 60\n",
      "7/20\n",
      "\n",
      "\n",
      "32_dims_100000_samples 2\n",
      "trial_5 49\n",
      "0/20\n",
      "\n",
      "\n",
      "512_dims_10000_samples 3\n",
      "trial_1 60\n",
      "trial_2 60\n",
      "trial_3 11\n",
      "2/20\n",
      "\n",
      "\n",
      "512_dims_1000_samples 3\n",
      "trial_1 60\n",
      "trial_2 60\n",
      "trial_3 60\n",
      "3/20\n",
      "\n",
      "\n",
      "64_dims_100000_samples 21\n",
      "trial_1 60\n",
      "trial_10 59\n",
      "trial_11 59\n",
      "trial_12 57\n",
      "trial_13 56\n",
      "trial_14 51\n",
      "trial_15 49\n",
      "trial_16 45\n",
      "trial_17 39\n",
      "trial_18 25\n",
      "trial_19 10\n",
      "trial_2 60\n",
      "trial_20 2\n",
      "trial_21 1\n",
      "trial_3 60\n",
      "trial_4 60\n",
      "trial_5 60\n",
      "trial_6 60\n",
      "trial_7 60\n",
      "trial_8 60\n",
      "8/20\n",
      "\n",
      "\n",
      "64_dims_10000_samples 1\n",
      "0/20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TODO = get_stats('/Users/sob/Desktop/october/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TODO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135bd8962fa04b418490c1bc75ef8175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" MOVE HYPERTUNING RESULTS TO BEST FOLDER \"\"\"\n",
    "import tqdm\n",
    "best_path = '/Users/sob/Desktop/gan_results/best/multivariate/16_dims_10000_samples/'\n",
    "dirname = '/Users/sob/Desktop/gan_results/hypertuning/multivariate/16_dims_10000_samples/'\n",
    "if not os.path.exists(best_path):\n",
    "    os.makedirs(best_path)\n",
    "\n",
    "files = [f for f in files if f != '.DS_Store']\n",
    "for idx, f in tqdm.tqdm_notebook(enumerate(files)):\n",
    "    \n",
    "    optimal = get_best_performance_mnist(dirname + f + '/')\n",
    "    if len(os.listdir(dirname + f + '/')) < 60:\n",
    "        print(f, len(os.listdir(dirname + f + '/')))\n",
    "    \n",
    "    with open(best_path + '/trial_{0}.json'.format(idx+1), 'w') as outfile:\n",
    "        json.dump(optimal, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
