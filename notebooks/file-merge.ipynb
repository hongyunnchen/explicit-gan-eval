{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, shutil, itertools, json\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "\n",
    "def crawl_directory(dirname):\n",
    "    \"\"\" Walk a nested directory to get all filename ending in a pattern \"\"\"\n",
    "    for path, subdirs, files in os.walk(dirname):\n",
    "        for name in files:\n",
    "            if not name.endswith('.DS_Store'):\n",
    "                yield os.path.join(path, name)\n",
    "\n",
    "\n",
    "def remove_empty_dirs(path):\n",
    "    for root, dirnames, filenames in os.walk(path, topdown=False):\n",
    "        for dirname in dirnames:\n",
    "            remove_empty_dir(os.path.realpath(os.path.join(root, dirname)))\n",
    "\n",
    "\n",
    "def remove_empty_dir(path):\n",
    "    try:\n",
    "        os.rmdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def nested_pickle_dict():\n",
    "    \"\"\" Picklable defaultdict nested dictionaries \"\"\"\n",
    "    return defaultdict(nested_pickle_dict)\n",
    "\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return (a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]).lower()\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, axis=1, confidence=0.95):\n",
    "    try:\n",
    "        n = data.shape[axis]\n",
    "    except IndexError:\n",
    "        axis = 0\n",
    "        n = data.shape[axis]\n",
    "\n",
    "    mu, std = np.nanmean(data, axis=axis), scipy.stats.sem(data, axis=axis, nan_policy='omit')\n",
    "    h = np.ma.getdata(std) * scipy.stats.t.ppf((1 + confidence) / 2., n-1)       \n",
    "\n",
    "    return mu, h, mu-h, mu+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78b271dfdc346e180de29915f1677cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128_dims_100000_samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74b74f9becf4fdcab9cb67c61475322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sob/Desktop/gan_results/best_hyper/multivariate/128_dims_100000_samples/\n",
      "128_dims_10000_samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a117b9c0a5b4409bb2bbcd77a17771b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sob/Desktop/gan_results/best_hyper/multivariate/128_dims_10000_samples/\n",
      "128_dims_1000_samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbbd110b1e24254bcb72b93b4cb07b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sob/Desktop/gan_results/best_hyper/multivariate/128_dims_1000_samples/\n",
      "16_dims_100000_samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3facec35353400b9b13631c283e7fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Get best performance according to hyperparameter mean minimum \"\"\"\n",
    "\n",
    "dirname = '/Users/sob/Desktop/gan_results/hypertuning/multivariate/'\n",
    "\n",
    "# Same for all..\n",
    "resultnames = [i for i in os.listdir(dirname + '16_dims_1000_samples/trial_1') if i != '.DS_Store']\n",
    "tuningnames = [i for i in os.listdir(dirname) if i != '.DS_Store']\n",
    "\n",
    "for t in tqdm_notebook(tuningnames):\n",
    "    \n",
    "    print(t)\n",
    "    \n",
    "    best_path = '/Users/sob/Desktop/gan_results/best_hyper/multivariate/{0}/'.format(t)\n",
    "    global_optimal = nested_pickle_dict()\n",
    "\n",
    "    # Initialize best dictionary    \n",
    "    for name in tqdm_notebook(resultnames):\n",
    "\n",
    "        optimal = nested_pickle_dict()\n",
    "        results = []\n",
    "\n",
    "        # Load in the results from each trial\n",
    "        for trial in range(1, 21):\n",
    "            path = '/Users/sob/Desktop/gan_results/hypertuning/multivariate/{0}/trial_{1}/{2}'.format(t, trial, name)\n",
    "            with open(path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            results.append(data)\n",
    "\n",
    "        # Go through each one and append the results\n",
    "        for result in results:\n",
    "            for model, distributions in result.items():\n",
    "                for distribution, metrics in distributions.items():\n",
    "                    for metric, values in metrics.items():\n",
    "                        if metric in [\"LR\", \"HDIM\", 'GLoss', 'DLoss', \"BSIZE\", \"Energy-Distance\"]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            # If metric is seen for the first time, initialize it\n",
    "                            if 'values' not in optimal[model][distribution][metric]:\n",
    "                                optimal[model][distribution][metric][\"values\"] = []\n",
    "\n",
    "                            # Otherwise, compare it the presently considered value\n",
    "                            optimal[model][distribution][metric][\"values\"].append(values)\n",
    "\n",
    "        for model, distributions in result.items():\n",
    "            for distribution, metrics in distributions.items():\n",
    "                for metric, values in metrics.items():\n",
    "                    if metric in [\"LR\", \"HDIM\", 'GLoss', 'DLoss', \"BSIZE\", \"Energy-Distance\"]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        data_min = np.nanmean(np.nanmin(np.array(optimal[model][distribution][metric][\"values\"]), axis=1))\n",
    "                        \n",
    "                        # Init global optimal\n",
    "                        if 'best' not in global_optimal[model][distribution][metric]:\n",
    "                            global_optimal[model][distribution][metric]['best'] = 1e10     \n",
    "\n",
    "                        if data_min < global_optimal[model][distribution][metric]['best']:\n",
    "#                             print(model, distribution, metric, '\\n', global_optimal[model][distribution][metric]['best'], '-->', data_min, '\\n')\n",
    "                            global_optimal[model][distribution][metric]['best'] = data_min\n",
    "                            global_optimal[model][distribution][metric]['parameters'] = [metrics[\"LR\"], metrics[\"HDIM\"], metrics[\"BSIZE\"]]\n",
    "                            global_optimal[model][distribution][metric][\"values\"] = optimal[model][distribution][metric][\"values\"]\n",
    "            \n",
    "                            mean, h, low, high = mean_confidence_interval(np.array(optimal[model][distribution][metric][\"values\"]))\n",
    "                \n",
    "                            global_optimal[model][distribution][metric]['low'] = list(low)\n",
    "                            global_optimal[model][distribution][metric]['h'] = list(h)\n",
    "                            global_optimal[model][distribution][metric]['mean'] = list(mean)\n",
    "                            global_optimal[model][distribution][metric]['high'] = list(high)\n",
    "\n",
    "    if not os.path.exists(best_path):\n",
    "        os.makedirs(best_path)\n",
    "    \n",
    "    with open(best_path + 'data.json', 'w') as outfile:\n",
    "        json.dump(global_optimal, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_optimal[model][distribution]['KL-Divergence'][\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path = '../best/' + '/'.join(dirname.split('/')[-3:])\n",
    "if not os.path.exists(best_path):\n",
    "    os.makedirs(best_path)\n",
    "\n",
    "files = os.listdir(dirname)\n",
    "files = [f for f in files if f != '.DS_Store']\n",
    "for idx, f in tqdm.tqdm_notebook(enumerate(files)):\n",
    "\n",
    "    optimal = get_best_performance_mnist(dirname + f + '/')\n",
    "    if len(os.listdir(dirname + f + '/')) < 60:\n",
    "        print(f, len(os.listdir(dirname + f + '/')))\n",
    "\n",
    "    with open(best_path + '/trial_{0}.json'.format(idx+1), 'w') as outfile:\n",
    "        json.dump(optimal, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_optimums[model][distribution]['Wasserstein-Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_performance_multivariate(mypath):\n",
    "    \"\"\" For a trial, get the best performance for multivariate data according to any hyperparam \"\"\"\n",
    "    # Get path, files in path\n",
    "    files = os.listdir(mypath)\n",
    "    results = []\n",
    "\n",
    "    # Read in the files\n",
    "    for file in files:\n",
    "        if file == '.DS_Store':\n",
    "            continue\n",
    "                            \n",
    "        with open(mypath + file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        results.append(data)\n",
    "        \n",
    "    # Initialize best dictionary\n",
    "    optimal = nested_pickle_dict()\n",
    "\n",
    "    # Go through all models, distributionss, metrics, and record the best\n",
    "    for result in results:\n",
    "        for model, distributions in result.items():\n",
    "            for distribution, metrics in distributions.items():\n",
    "                for metric, values in metrics.items():\n",
    "                    if metric not in [\"LR\", \"HDIM\", \"BSIZE\"]:\n",
    "\n",
    "                        # If metric is seen for the first time, it is the best\n",
    "                        if metric not in optimal[model][distribution]:\n",
    "                            optimal[model][distribution][metric][\"value\"] = values\n",
    "                            optimal[model][distribution][metric][\"parameters\"] = [metrics[\"LR\"], metrics[\"HDIM\"], metrics[\"BSIZE\"]]\n",
    "\n",
    "                        # Otherwise, compare it the presently considered value\n",
    "                        elif min(optimal[model][distribution][metric][\"value\"]) > min(values):\n",
    "                            optimal[model][distribution][metric][\"value\"] = values\n",
    "                            optimal[model][distribution][metric][\"parameters\"] = [metrics[\"LR\"], metrics[\"HDIM\"], metrics[\"BSIZE\"]]\n",
    "\n",
    "    return optimal\n",
    "\n",
    "\n",
    "def get_best_performance_mnist(*args):\n",
    "    return get_best_performance_multivariate(*args)\n",
    "\n",
    "\n",
    "def multivariate_hypertuning2best(dirname='/Users/sob/Desktop/gan_results/hypertuning/multivariate/64_dims_100000_samples/'):\n",
    "    \"\"\" MOVE HYPERTUNING RESULTS TO BEST FOLDER \"\"\"\n",
    "    best_path = '../best/' + '/'.join(dirname.split('/')[-3:])\n",
    "    if not os.path.exists(best_path):\n",
    "        os.makedirs(best_path)\n",
    "\n",
    "    files = os.listdir(dirname)\n",
    "    files = [f for f in files if f != '.DS_Store']\n",
    "    for idx, f in tqdm.tqdm_notebook(enumerate(files)):\n",
    "\n",
    "        optimal = get_best_performance_mnist(dirname + f + '/')\n",
    "        if len(os.listdir(dirname + f + '/')) < 60:\n",
    "            print(f, len(os.listdir(dirname + f + '/')))\n",
    "\n",
    "        with open(best_path + '/trial_{0}.json'.format(idx+1), 'w') as outfile:\n",
    "            json.dump(optimal, outfile)\n",
    "\n",
    "\n",
    "def merge_mixture(dirname):\n",
    "    outdir = dirname\n",
    "    for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        for nest in crawl_directory(dirname + file):\n",
    "\n",
    "            index = 1\n",
    "\n",
    "            if 'dims' not in nest.split('/')[7]:\n",
    "                outdir = '/'.join(nest.split('/')[:7] + nest.split('/')[8:9]) + '/'\n",
    "            else:\n",
    "                outdir = dirname\n",
    "                \n",
    "            # Initialize directory\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            try:\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "            except:\n",
    "                extension = nest.split('/')[-1]\n",
    "                while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                    index += 1\n",
    "\n",
    "                if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                    os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "    remove_empty_dirs(dirname)\n",
    "    \n",
    "    \n",
    "def merge_multivariate(dirname):\n",
    "    outdir = dirname\n",
    "    for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        for nest in crawl_directory(dirname + file):\n",
    "\n",
    "            index = 1\n",
    "\n",
    "            if 'dims' not in nest.split('/')[6]:\n",
    "                outdir = '/'.join(nest.split('/')[:7] + nest.split('/')[8:9]) + '/'\n",
    "            else:\n",
    "                # Uncomment the + for mixture\n",
    "                outdir = dirname + nest.split('/')[6] + '/'\n",
    "                \n",
    "            # Initialize directory\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            try:\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "            except:\n",
    "                extension = nest.split('/')[-1]\n",
    "                while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                    index += 1\n",
    "\n",
    "                if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                    os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "    remove_empty_dirs(dirname)\n",
    "    \n",
    "    \n",
    "def merge_mnist(dirname):\n",
    "    outdir = dirname\n",
    "    for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        for nest in crawl_directory(dirname + file):\n",
    "\n",
    "            index = 1\n",
    "\n",
    "            if 'dims' in nest.split('/')[5]:\n",
    "                outdir = '/'.join(nest.split('/')[:6]) + '/'\n",
    "            else:\n",
    "                # Uncomment the + for mixture\n",
    "                outdir = dirname + nest.split('/')[7] + '/'\n",
    "    \n",
    "\n",
    "            # Initialize directory\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            try:\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "            except:\n",
    "                extension = nest.split('/')[-1]\n",
    "                while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                    index += 1\n",
    "\n",
    "                if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                    os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "                shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "    remove_empty_dirs(dirname)\n",
    "    \n",
    "\n",
    "def get_stats(dirname):\n",
    "    \"\"\" Get missing runs for all trials \"\"\"\n",
    "    hidden_dims = [32, 64, 128, 256, 512]\n",
    "    batch_sizes = [128, 256, 512, 1024]\n",
    "    learning_rates = [2e-1, 2e-2, 2e-3]\n",
    "\n",
    "    filenames, hyperparams = [], []\n",
    "\n",
    "    for (lr, hdim, bsize) in itertools.product(*[learning_rates, hidden_dims, batch_sizes]):\n",
    "        hyperparam = (lr * min(batch_sizes)/bsize, hdim, bsize)\n",
    "        filename = 'results_{0}.json'.format(\"_\".join([str(i) for i in hyperparam]))\n",
    "        filenames.append(filename)\n",
    "        hyperparams.append((str(format_e(lr)), str(hdim), str(bsize)))\n",
    "    \n",
    "    TODO = []\n",
    "    for file in os.listdir(dirname):\n",
    "        if '.DS_Store' in file:\n",
    "            continue\n",
    "\n",
    "        print(file, len(os.listdir(dirname + file)))\n",
    "        idx = 0\n",
    "        try:\n",
    "            for f in os.listdir(dirname + file):\n",
    "                if '.DS_Store' in f:\n",
    "                    continue\n",
    "\n",
    "                files = os.listdir(dirname + file + '/' + f)\n",
    "                length = len(files)\n",
    "                print(f, length)\n",
    "\n",
    "                if length >= 60:\n",
    "                    idx += 1            \n",
    "                else:\n",
    "                    missing = [hyperparams[idx] for idx, item in enumerate(filenames) if item not in files]\n",
    "                    TODO.extend(missing)\n",
    "\n",
    "            print('{0}/20'.format(idx))\n",
    "            print('\\n')\n",
    "        except NotADirectoryError:\n",
    "            files = os.listdir(dirname + file)\n",
    "            missing = [hyperparams[idx] for idx, item in enumerate(filenames) if item not in files]\n",
    "            TODO.extend(missing)\n",
    "            \n",
    "        \n",
    "    return TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/Users/sob/Desktop/apple/64_dims_100000_samples/'\n",
    "outdir = dirname\n",
    "for idx, file in enumerate(os.listdir(dirname)):\n",
    "\n",
    "    if '.DS_Store' in file:\n",
    "        continue\n",
    "\n",
    "    for nest in crawl_directory(dirname + file):\n",
    "\n",
    "        index = 1\n",
    "\n",
    "        if 'dims' not in nest.split('/')[6]:\n",
    "            outdir = '/'.join(nest.split('/')[:6]) + '/'# + nest.split('/')[8:9]) + '/'\n",
    "        else:\n",
    "            # Uncomment the + for mixture\n",
    "            outdir = dirname + nest.split('/')[6]\n",
    "        \n",
    "        print(outdir)\n",
    "            \n",
    "#        # Initialize directory\n",
    "        if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "            os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "        try:\n",
    "            shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "        except:\n",
    "            extension = nest.split('/')[-1]\n",
    "            while os.path.exists(outdir + 'trial_{0}/'.format(index) + extension):\n",
    "                index += 1\n",
    "\n",
    "            if not os.path.exists(outdir + 'trial_{0}/'.format(index)):\n",
    "                os.makedirs(outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "            shutil.move(nest, outdir + 'trial_{0}/'.format(index))\n",
    "\n",
    "remove_empty_dirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" MOVE HYPERTUNING RESULTS TO BEST FOLDER \"\"\"\n",
    "import tqdm\n",
    "best_path = '/Users/sob/Desktop/gan_results/best/multivariate/64_dims_100000_samples/'\n",
    "dirname = '/Users/sob/Desktop/gan_results/hypertuning/multivariate/64_dims_100000_samples/'\n",
    "if not os.path.exists(best_path):\n",
    "    os.makedirs(best_path)\n",
    "\n",
    "files = os.listdir(dirname)\n",
    "files = [f for f in files if f != '.DS_Store']\n",
    "for idx, f in tqdm.tqdm_notebook(enumerate(files)):\n",
    "    \n",
    "    optimal = get_best_performance_mnist(dirname + f + '/')\n",
    "    if len(os.listdir(dirname + f + '/')) < 60:\n",
    "        print(f, len(os.listdir(dirname + f + '/')))\n",
    "    \n",
    "    with open(best_path + '/trial_{0}.json'.format(idx+1), 'w') as outfile:\n",
    "        json.dump(optimal, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
